import json, re
from collections import Counter, defaultdict

with open("questions.json", "r", encoding="utf-8") as f:
    questions = json.load(f)

STOP_WORDS = {'the','a','an','is','are','of','in','to','for','and','or','which','what',
              'following','not','does','that','this','it','by','on','from','with','be',
              'how','do','was','has','have','can','will','one','its','used','called',
              'type','system','operating','os','process','when','between','if','all','none',
              'true','false','above','mentioned','these','both','more','most'}

# Questions already solved by earlier rules (from simulation)
ALREADY_SOLVED = set()
TIER1 = ['circular','unauthorized','wait','pages','switching','than','create','web','allows','among','highest']
TIER2 = ['ready','each','compiling','part','executing']
TRAP_WORDS = ['single','allocates','prevention','prevent','prevents','preventing','prevented',
              'reduce','reduces','reduced','reducing','reduction','macos','segmentation','deadlocks','speed','manager']

def clean(text):
    return re.sub(r'^[a-d]\)\s*', '', text.strip())

# First pass: identify which questions are solved by earlier rules
for q in questions:
    opts = [(clean(o["text"]), o["correct"]) for o in q["options"]]
    qtext = q["text"]
    is_not = bool(re.search(r'\bnot\b', qtext, re.IGNORECASE))
    
    # All/None/TF/Schedules/Traps
    if len(opts) == 2: ALREADY_SOLVED.add(q['id']); continue
    if any(re.search(r'\ball\s+(of\s+)?(the\s+)?(mentioned|above)', t, re.IGNORECASE) for t,c in opts):
        ALREADY_SOLVED.add(q['id']); continue
    
    # Check if Tier 1 or 2 uniquely solves it
    non_none = [(t,c) for t,c in opts if not re.search(r'\bnone\b', t, re.IGNORECASE)]
    for kw in TIER1:
        matching = [t for t,c in non_none if kw in t.lower().split()]
        if len(matching) == 1:
            ALREADY_SOLVED.add(q['id']); break

print(f"Ø£Ø³Ø¦Ù„Ø© Ù…Ø­Ù„ÙˆÙ„Ø© Ù…Ø³Ø¨Ù‚Ø§Ù‹: {len(ALREADY_SOLVED)}/180")
print(f"Ø£Ø³Ø¦Ù„Ø© Ù…ØªØ¨Ù‚ÙŠØ© Ù„Ù„ØªØ­Ù„ÙŠÙ„: {180 - len(ALREADY_SOLVED)}")

# Second pass: analyze duplicate keyword ONLY on unsolved questions
remaining_qs = [q for q in questions if q['id'] not in ALREADY_SOLVED]

# Per-word accuracy tracking
word_stats = defaultdict(lambda: {'total': 0, 'correct_in_pair': 0, 'questions': []})

for q in remaining_qs:
    opts = [(clean(o["text"]), o["correct"]) for o in q["options"]]
    correct_idx = next(i for i,(t,c) in enumerate(opts) if c)
    
    # Find words in exactly 2 options
    word_to_opts = {}
    for i, (text, _) in enumerate(opts):
        words = set(re.findall(r'[a-zA-Z]+', text.lower()))
        for w in words:
            if w in STOP_WORDS or len(w) <= 2:
                continue
            if w not in word_to_opts:
                word_to_opts[w] = []
            word_to_opts[w].append(i)
    
    pair_words = {w: indices for w, indices in word_to_opts.items() if len(indices) == 2}
    
    for word, indices in pair_words.items():
        word_stats[word]['total'] += 1
        if correct_idx in indices:
            word_stats[word]['correct_in_pair'] += 1
            word_stats[word]['questions'].append(f"Q{q['id']}âœ…")
        else:
            word_stats[word]['questions'].append(f"Q{q['id']}âŒ")

# Sort by total appearances
print(f"\n{'='*70}")
print("ðŸ“Š Ø¯Ù‚Ø© ÙƒÙ„ ÙƒÙ„Ù…Ø© Ù…ÙƒØ±Ø±Ø© (Ø¨Ø¹Ø¯ Ø§Ø³ØªØ¨Ø¹Ø§Ø¯ Ø§Ù„Ù…Ø­Ù„ÙˆÙ„ Ù…Ø³Ø¨Ù‚Ø§Ù‹)")
print(f"{'='*70}")

print(f"\n--- ÙƒÙ„Ù…Ø§Øª Ø¸Ù‡Ø±Øª 3+ Ù…Ø±Ø§Øª (Ø£Ù…ÙƒÙ† Ù†Ø«Ù‚ ÙÙŠÙ‡Ø§) ---")
for word, stats in sorted(word_stats.items(), key=lambda x: -x[1]['total']):
    if stats['total'] >= 3:
        pct = stats['correct_in_pair'] * 100 // stats['total']
        emoji = "ðŸŸ¢" if pct >= 75 else ("ðŸŸ¡" if pct >= 50 else "ðŸ”´")
        print(f"  {emoji} \"{word}\": {stats['correct_in_pair']}/{stats['total']} = {pct}% â€” {', '.join(stats['questions'])}")

print(f"\n--- ÙƒÙ„Ù…Ø§Øª Ø¸Ù‡Ø±Øª Ù…Ø±ØªÙŠÙ† ---")
for word, stats in sorted(word_stats.items(), key=lambda x: -x[1]['correct_in_pair']):
    if stats['total'] == 2:
        pct = stats['correct_in_pair'] * 100 // stats['total']
        emoji = "ðŸŸ¢" if pct >= 75 else ("ðŸŸ¡" if pct >= 50 else "ðŸ”´")
        print(f"  {emoji} \"{word}\": {stats['correct_in_pair']}/{stats['total']} = {pct}% â€” {', '.join(stats['questions'])}")

# Overall accuracy on remaining questions only
total_with_pairs = 0
correct_pairs = 0
for q in remaining_qs:
    opts = [(clean(o["text"]), o["correct"]) for o in q["options"]]
    correct_idx = next(i for i,(t,c) in enumerate(opts) if c)
    
    word_to_opts = {}
    for i, (text, _) in enumerate(opts):
        words = set(re.findall(r'[a-zA-Z]+', text.lower()))
        for w in words:
            if w in STOP_WORDS or len(w) <= 2:
                continue
            if w not in word_to_opts:
                word_to_opts[w] = []
            word_to_opts[w].append(i)
    
    pair_words = {w: indices for w, indices in word_to_opts.items() if len(indices) == 2}
    if pair_words:
        total_with_pairs += 1
        # Is correct answer in ANY pair?
        for w, indices in pair_words.items():
            if correct_idx in indices:
                correct_pairs += 1
                break

print(f"\n{'='*70}")
print(f"ðŸ“Š Ø§Ù„Ø¯Ù‚Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ØºÙŠØ± Ù…Ø­Ù„ÙˆÙ„Ø© ÙÙ‚Ø·:")
print(f"  Ø£Ø³Ø¦Ù„Ø© ÙÙŠÙ‡Ø§ Ù†Ù…Ø·: {total_with_pairs}/{len(remaining_qs)}")
print(f"  Ø§Ù„Ø¬ÙˆØ§Ø¨ Ø£Ø­Ø¯ Ø§Ù„Ø®ÙŠØ§Ø±ÙŠÙ†: {correct_pairs}/{total_with_pairs} = {correct_pairs*100//total_with_pairs if total_with_pairs else 0}%")

# Find HIGH accuracy words (>=75%) that appear 2+ times
print(f"\n{'='*70}")
print(f"ðŸŽ¯ ÙƒÙ„Ù…Ø§Øª Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø¯Ù‚Ø© (â‰¥75%ØŒ Ø¸Ù‡Ø±Øª 2+ Ù…Ø±Ø©):")
good_words = []
for word, stats in sorted(word_stats.items(), key=lambda x: -x[1]['total']):
    if stats['total'] >= 2:
        pct = stats['correct_in_pair'] * 100 // stats['total']
        if pct >= 75:
            good_words.append(word)
            print(f"  âœ… \"{word}\": {stats['correct_in_pair']}/{stats['total']} = {pct}%")

print(f"\n  Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹: {len(good_words)} ÙƒÙ„Ù…Ø© Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø¯Ù‚Ø©")
